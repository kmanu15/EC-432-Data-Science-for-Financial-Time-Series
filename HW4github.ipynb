{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16fa6651-9965-44f3-a665-455b59f9e1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import t\n",
    "from scipy.stats import norm\n",
    "from math import exp\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19dc9293-0553-456e-bd61-84a4d5927cce",
   "metadata": {},
   "source": [
    "## 1. This exercise analyzes daily data for MSFT from January 2, 2012, to December 31, 2024. Using the adjusted closing prices, compute the daily log returns. Although some autocorrelation and volatility clustering may be present, assume that the returns are i.i.d. For bootstrapping, set $B = 1000$ and use a random seed of 432 (i.e., np.random.seed(432)inPython). TheinitialinvestmentisW0 =105."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43250eee-4cfe-41df-9cd9-0ddd3e53172d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39b58fdf-bed0-4a55-a5b2-69843a940e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Ticker</th>\n",
       "      <th>Date</th>\n",
       "      <th>MSFT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3268</td>\n",
       "      <td>3268.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2018-07-02 16:39:48.249694208</td>\n",
       "      <td>0.000918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2012-01-04 00:00:00</td>\n",
       "      <td>-0.159453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2015-04-06 18:00:00</td>\n",
       "      <td>-0.006706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2018-07-02 12:00:00</td>\n",
       "      <td>0.000728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2021-09-29 06:00:00</td>\n",
       "      <td>0.009340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2024-12-30 00:00:00</td>\n",
       "      <td>0.132929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.016364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Ticker                           Date         MSFT\n",
       "count                            3268  3268.000000\n",
       "mean    2018-07-02 16:39:48.249694208     0.000918\n",
       "min               2012-01-04 00:00:00    -0.159453\n",
       "25%               2015-04-06 18:00:00    -0.006706\n",
       "50%               2018-07-02 12:00:00     0.000728\n",
       "75%               2021-09-29 06:00:00     0.009340\n",
       "max               2024-12-30 00:00:00     0.132929\n",
       "std                               NaN     0.016364"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Microsoft daily adjusted closing prices\n",
    "msft = yf.download('MSFT', start = '2012-01-02', end = '2024-12-31', interval = '1d',\n",
    "                  auto_adjust = False)['Adj Close']\n",
    "\n",
    "# Convert to log returns\n",
    "log_returns = np.log(msft / msft.shift(1))\n",
    "log_returns = log_returns.dropna().reset_index()\n",
    "log_returns.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6ac7771-d50b-4c10-9a01-7bf5a44d364c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed\n",
    "np.random.seed(432)\n",
    "\n",
    "# For bootstrapping\n",
    "B = 1000\n",
    "\n",
    "# Initial Investment\n",
    "W_0 = 10e+5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150bfd39-b21a-40e1-919b-814ad0e77c03",
   "metadata": {},
   "source": [
    "### (a) Compute nonparametric estimates of VaR$_{0.01}$ and ES$_{0.01}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3144abf1-fcbe-416f-a834-06e37f4048e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The nonparametric estimation of VaR_0.01 = -42095.949\n"
     ]
    }
   ],
   "source": [
    "# Sort the returns\n",
    "sorted_returns = log_returns.sort_values('MSFT').reset_index()\n",
    "\n",
    "# product of n and alpha\n",
    "index = int(.01*len(log_returns))\n",
    "\n",
    "# get r_na\n",
    "r_na = sorted_returns['MSFT'].iloc[index]\n",
    "\n",
    "# Calculate non parametric VaR\n",
    "npVaR_01 = W_0 * (np.exp(r_na) - 1)\n",
    "print('The nonparametric estimation of VaR_0.01 =', np.round(npVaR_01, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c64e8691-973b-4d1a-b366-9ec59758f35e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The nonparametic estimatino of ES = -59888.657\n"
     ]
    }
   ],
   "source": [
    "# Profit\n",
    "X_t = W_0 * (np.exp(log_returns['MSFT']) -1)\n",
    "\n",
    "# calculate nonparametric ES\n",
    "npES = np.mean(X_t * (X_t <= npVaR_01)) / 0.01\n",
    "\n",
    "print('The nonparametic estimatino of ES =', np.round(npES, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab312d48-6441-44ef-b54c-007e56836f43",
   "metadata": {},
   "source": [
    "### (b) Compute parametric estimates of VaR$_{0.01}$ and ES$_{0.01}$ assuming that the returns are normally distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ac37842-cf2e-4c3c-8a9f-0338e9069980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The parametric estimation of VaR_0.01 assuming r_t is normally distributed is -36462.196\n"
     ]
    }
   ],
   "source": [
    "# Parametric normal VaR\n",
    "mu_hat, sigma_hat = norm.fit(log_returns['MSFT'])\n",
    "norm_VaR_01 = W_0 * (np.exp(mu_hat + sigma_hat * norm.ppf(0.01)) - 1)\n",
    "\n",
    "print('The parametric estimation of VaR_0.01 assuming r_t is normally distributed is', \n",
    "      np.round(norm_VaR_01, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "caf1a05a-17e8-4ec7-8d60-62b0c4aa2744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The corresponding parametric estimation of ES = -92046.504\n"
     ]
    }
   ],
   "source": [
    "# Parametric ES\n",
    "norm_ES = np.mean(X_t * (X_t <= norm_VaR_01)) / 0.01\n",
    "\n",
    "print('The corresponding parametric estimation of ES =', np.round(norm_ES, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfb4015-bed4-464e-b52a-4ddc1e20565e",
   "metadata": {},
   "source": [
    "### (c) Compute parametric estimates of VaR$_{0.01}$ and ES$_{0.01}$ assuming that assuming that the returns are $t$-distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe7ce692-446e-41b8-9eda-4f3b82c07d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The parametric estimation of VaR_0.01 assuming r_t is t-distributed is -42949.819\n"
     ]
    }
   ],
   "source": [
    "# fit t-distribution to data\n",
    "v_hat, mu_hat, sigma_hat = t.fit(log_returns['MSFT'])\n",
    "\n",
    "# parametric t-distributed VaR\n",
    "t_VaR_01 = W_0 * (np.exp(mu_hat + sigma_hat * t.ppf(0.01, df=v_hat)) - 1)\n",
    "\n",
    "print('The parametric estimation of VaR_0.01 assuming r_t is t-distributed is', np.round(t_VaR_01, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8aecffb-2cbb-49a4-83e6-641a634155c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The corresponding parametric estimation of ES = -56007.65\n"
     ]
    }
   ],
   "source": [
    "# Parametric ES\n",
    "t_ES = np.mean(X_t * (X_t <= t_VaR_01)) / 0.01\n",
    "\n",
    "print('The corresponding parametric estimation of ES =', np.round(t_ES, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472428df-cba2-455e-b4e5-78d48d2bdea6",
   "metadata": {},
   "source": [
    "### (d) Compare the estimates in (a), (b), and (c). Which do you feel are most realistic?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c683f8-e6aa-4943-a9a4-910eb496590d",
   "metadata": {},
   "source": [
    "The nonparametric VaR estimate is likely the most realistic, since it avoids strong distributional assumptions and reflects the empirical distribution of returns. The normal distribution estimates the least tail risk, while the t-distribution estimates the most tail risk. The nonparametric method, while sample-dependent, offers the most direct and assumption-free estimate of risk."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e41420-2775-4807-8607-d82d305a033e",
   "metadata": {},
   "source": [
    "### (e) Construct 95% symmetric bootstrap confidence intervals for VaR$_{0.01}$ and ES$_{0.01}$ using nonparametric estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eac8e453-bb48-4aa4-b439-d3699639774a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrapping\n",
    "boot_samples = np.zeros((B, 2))\n",
    "n = len(log_returns)\n",
    "\n",
    "for i in range(B):\n",
    "    \n",
    "    # Create bootstrap sample w/ replacement\n",
    "    sample_returns = np.random.choice(log_returns['MSFT'], replace = True, size=n)\n",
    "    sorted_returns = np.sort(sample_returns) # sort returns\n",
    "    rb_na = sorted_returns[index] # alpha sample quantile\n",
    "    Xb_t = W_0 * (np.exp(sample_returns) - 1)\n",
    "    \n",
    "    # estimate VaR\n",
    "    VaR_est = W_0 * (np.exp(rb_na) - 1)\n",
    "\n",
    "    # Estimate ES\n",
    "    ES_est = np.mean(Xb_t * (Xb_t <= VaR_est)) / 0.01\n",
    "    \n",
    "    # list of estimated VaR's\n",
    "    boot_samples[i] = [VaR_est, ES_est]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c768618b-ab92-46a6-8404-74660be9f3f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 95% symmetric bootstrap confidence interval for the nonparametric estimation of VaR_01 is [-44497.208 -39694.691]\n"
     ]
    }
   ],
   "source": [
    "# Theta distribution of VaR\n",
    "theta_dist = boot_samples[:, 0] - npVaR_01\n",
    "\n",
    "# 95th quantile\n",
    "q_95 = np.percentile(theta_dist, 95)\n",
    "\n",
    "# Symmetric 95% confidence interval\n",
    "VaR_ci = [npVaR_01 - q_95, npVaR_01 + q_95]\n",
    "print('The 95% symmetric bootstrap confidence interval for the nonparametric estimation of VaR_01 is', \n",
    "      np.round(VaR_ci, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad823172-e3a7-4d0d-a785-732efb22053b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 95% symmetric bootstrap confidence interval for the nonparametric estimation of ES_01 is [-66988.099 -52789.214]\n"
     ]
    }
   ],
   "source": [
    "# Theta distribution of ES\n",
    "theta_dist = boot_samples[:, 1] - npES\n",
    "\n",
    "# 95th percentile\n",
    "q_95 = np.percentile(theta_dist, 95)\n",
    "\n",
    "# Symmetric 95% confidence interval\n",
    "ES_ci = [npES - q_95, npES + q_95]\n",
    "print('The 95% symmetric bootstrap confidence interval for the nonparametric estimation of ES_01 is', \n",
    "      np.round(ES_ci, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e61a2a4-0739-4f5b-8bcb-9c09906441c2",
   "metadata": {},
   "source": [
    "### (f) Estimate the left tail index via regression (set m = 0:1n). Using $\\alpha_0 = 0.01$, compute VaR$_{0.001}$ and ES$_{0.001}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0efa6ae-fd5f-406f-a985-708be4f6e610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.969\n",
      "Model:                            OLS   Adj. R-squared:                  0.969\n",
      "Method:                 Least Squares   F-statistic:                 1.011e+04\n",
      "Date:                Mon, 22 Sep 2025   Prob (F-statistic):          2.19e-246\n",
      "Time:                        22:02:21   Log-Likelihood:                 114.73\n",
      "No. Observations:                 326   AIC:                            -225.5\n",
      "Df Residuals:                     324   BIC:                            -217.9\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         23.9437      0.271     88.357      0.000      23.411      24.477\n",
      "x1             2.6782      0.027    100.571      0.000       2.626       2.731\n",
      "==============================================================================\n",
      "Omnibus:                       53.015   Durbin-Watson:                   0.031\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               81.084\n",
      "Skew:                          -0.993   Prob(JB):                     2.47e-18\n",
      "Kurtosis:                       4.424   Cond. No.                         294.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Calculate the sample size\n",
    "n = len(log_returns)\n",
    "# Set the significance level alpha_0\n",
    "alpha_0 = 0.1\n",
    "# Calculate the number of extreme values to use (m = alpha_0 * n)\n",
    "m = int(n * alpha_0)\n",
    "\n",
    "# Create an array of indices from 1 to m\n",
    "i_vals = np.arange(1, m+1)\n",
    "\n",
    "# Calculate log(i/n) which will be the dependent variable in the regression\n",
    "log = np.log(i_vals / n)\n",
    "\n",
    "# Sort the returns in ascending order\n",
    "X_t = np.sort(X_t)\n",
    "\n",
    "# Transform the extreme values using negative log of negative values\n",
    "Z_i = -np.log(-X_t[i_vals])\n",
    "\n",
    "# Add a constant term to the independent variables for the regression intercept\n",
    "X = sm.add_constant(Z_i)\n",
    "\n",
    "# Fit an Ordinary Least Squares regression model\n",
    "model = sm.OLS(log, X).fit()\n",
    "\n",
    "# Display the regression results summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f94b0034-7a19-465d-8eb8-be96c9cafe36",
   "metadata": {},
   "outputs": [],
   "source": [
    "kappa = model.params[1] # Extract the kappa parameter (second parameter) from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ec08b6c-532c-496f-9333-edbd9259f785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VaR_0.001 = -91037.64383230629\n",
      "ES_0.001 = -145283.54140661375\n"
     ]
    }
   ],
   "source": [
    "# Calculate Value at Risk (VaR) at alpha_0 confidence level\n",
    "VaR_alpha0 = X_t[int(n * alpha_0)]\n",
    "\n",
    "# Set target confidence level alpha for risk calculation\n",
    "alpha = 0.001\n",
    "\n",
    "# Calculate VaR at target confidence level using Pareto extrapolation\n",
    "# Formula: VaR_alpha = VaR_alpha0 * (alpha_0/alpha)^(1/kappa)\n",
    "VaR_alpha = VaR_alpha0 * (alpha_0 / alpha) ** (1 / kappa)\n",
    "\n",
    "print('VaR_0.001 =', VaR_alpha)\n",
    "\n",
    "# Calculate Expected Shortfall (ES) at target confidence level\n",
    "# For Pareto distribution, ES_alpha = (kappa/(kappa-1)) * VaR_alpha\n",
    "ES_alpha = (kappa / (kappa - 1)) * VaR_alpha\n",
    "\n",
    "print('ES_0.001 =', ES_alpha)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
